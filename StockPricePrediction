{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+3TjzvFio4U3Yji7+jACr"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVZqUBQSlZ8g"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "\n",
        "# Specify the stock ticker and the date range\n",
        "stock_ticker = 'AAPL'  # Apple Inc.\n",
        "start_date = '2023-01-01'\n",
        "end_date = '2023-12-31'\n",
        "\n",
        "# Fetch the data\n",
        "stock_data = yf.download(stock_ticker, start=start_date, end=end_date)\n",
        "\n",
        "# Save the data to a CSV file\n",
        "stock_data.to_csv('apple_stock_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load historical stock data\n",
        "data = pd.read_csv('apple_stock_data.csv')\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "\n",
        "# Feature Engineering\n",
        "data['Month'] = data['Date'].dt.month\n",
        "data['Day'] = data['Date'].dt.day\n",
        "\n",
        "# Prepare data for training\n",
        "data = data[['Close', 'Month', 'Day']].values\n",
        "\n",
        "# Normalize data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data = scaler.fit_transform(data)\n",
        "\n",
        "# Split data into train and test sets\n",
        "train_size = int(len(data) * 0.8)\n",
        "train_data, test_data = data[:train_size], data[train_size:]\n",
        "\n",
        "# Reshape data for LSTM\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(dataset) - look_back):\n",
        "        X.append(dataset[i:(i + look_back)])\n",
        "        Y.append(dataset[i + look_back][0])\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "look_back = 1\n",
        "train_X, train_Y = create_dataset(train_data, look_back)\n",
        "test_X, test_Y = create_dataset(test_data, look_back)\n",
        "\n",
        "train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[1], train_X.shape[2]))\n",
        "test_X = np.reshape(test_X, (test_X.shape[0], test_X.shape[1], test_X.shape[2]))\n",
        "\n",
        "# Build LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, input_shape=(look_back, train_X.shape[2])))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_X, train_Y, epochs=100, batch_size=32, verbose=1)\n",
        "\n",
        "# Make predictions\n",
        "predicted_prices = model.predict(test_X)\n",
        "predicted_prices = scaler.inverse_transform(np.concatenate((predicted_prices, test_data[:, 1:]), axis=1))[:, 0]\n",
        "\n",
        "# Visualize the results\n",
        "actual_prices = scaler.inverse_transform(test_data)[:, 0]\n",
        "plt.plot(actual_prices, label='Actual Prices')\n",
        "plt.plot(predicted_prices, label='Predicted Prices')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F5GsTK0l0iAJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}